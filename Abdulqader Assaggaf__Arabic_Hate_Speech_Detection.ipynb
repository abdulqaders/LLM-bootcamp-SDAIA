{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlGpLgIaxp9z"
      },
      "source": [
        "#Hate Speech Detection with AraBERT and HuggingFace\n",
        "In this assignment, we will be exploring the application of the AraBERT model specifically for the task of hate speech detection. We will use the AJGT Sentiment Analysis dataset from K. M. Alomari, H. M. ElSherif, and K. Shaalan, “Arabic tweets sentimental analysis using machine learning,” in Proceedings of the International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, pp. 602–610, Montreal, Canada, June 2017.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JwOAlV5xsGV"
      },
      "source": [
        "# Check which GPU we have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krFwQr32xqLv",
        "outputId": "27f0adfc-ce34-4d16-ba5c-c9be2fcd04c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    !nvidia-smi\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Thu Mar 28 17:02:06 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd6vAHTei6PQ"
      },
      "source": [
        "##Installing Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohWiDLEnxJA5",
        "outputId": "00eace7e-4470-484f-9614-650027f7629d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install farasapy\n",
        "!pip install pyarabic\n",
        "!git clone https://github.com/aub-mind/arabert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->transformers[torch])\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.28.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting farasapy\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy) (4.66.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2024.2.2)\n",
            "Installing collected packages: farasapy\n",
            "Successfully installed farasapy-0.0.14\n",
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pyarabic) (1.16.0)\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.15\n",
            "Cloning into 'arabert'...\n",
            "remote: Enumerating objects: 600, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 600 (delta 38), reused 45 (delta 30), pack-reused 535\u001b[K\n",
            "Receiving objects: 100% (600/600), 9.14 MiB | 27.86 MiB/s, done.\n",
            "Resolving deltas: 100% (339/339), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFxAnGMIx1qG"
      },
      "source": [
        "#Reading Data\n",
        "We will rely on the following libraries for training and evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl-z0SH0gR_C"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/komari6/Arabic-twitter-corpus-AJGT.git"
      ],
      "metadata": {
        "id": "VBYk072elB84",
        "outputId": "1a2720ae-37f6-418a-f4fc-85fffd37d720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Arabic-twitter-corpus-AJGT'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 9 (delta 0), reused 0 (delta 0), pack-reused 6\u001b[K\n",
            "Receiving objects: 100% (9/9), 102.95 KiB | 3.12 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1:** Read the dataset and arrange the columns name using the set variables:"
      ],
      "metadata": {
        "id": "8T1UM7HcoQkm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKFr-GcJjXEE"
      },
      "source": [
        "data = pd.read_excel('Arabic-twitter-corpus-AJGT/AJGT.xlsx')\n",
        "\n",
        "\n",
        "DATA_COLUMN = 'Feed'\n",
        "LABEL_COLUMN = 'Sentiment'\n",
        "INDEX_COLUMN = 'Index'\n",
        "\n",
        "data.columns = [INDEX_COLUMN, DATA_COLUMN, LABEL_COLUMN]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**: Split the data into training and testing (80-20)"
      ],
      "metadata": {
        "id": "K_zISEpsoOjs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFnvKJpojo2y"
      },
      "source": [
        "# Assuming 'data' is your DataFrame and 'target' is the label column\n",
        "X_train, X_test, Y_train, Y_test =  train_test_split(data[DATA_COLUMN], data[LABEL_COLUMN], test_size=0.20, random_state=42)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWF1oSY_jglL"
      },
      "source": [
        "**Question 3:** Plot the distribution of lengths of sentences in both training and test set. Extract the max_len value to be used later:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5seZqZp-cWK7",
        "outputId": "40335fe0-fe4a-427d-9246-513d72779917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "\n",
        "# Assuming 'X_train' and 'X_test' are your training and testing sets\n",
        "train_lengths = [len(s) for s in X_train]\n",
        "test_lengths = [len(s) for s in X_test]\n",
        "\n",
        "# Plotting the distributions\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.hist(train_lengths, bins=50, alpha=0.5, label='Train Set')\n",
        "plt.hist(test_lengths, bins=50, alpha=0.5, label='Test Set')\n",
        "plt.title('Distribution of Sentence Lengths')\n",
        "plt.xlabel('Sentence Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Extracting the max_len value\n",
        "max_len = max(max(train_lengths), max(test_lengths))\n",
        "print(f\"The maximum length of a sentence in the dataset is: {max_len}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum length of a sentence in the dataset is: 864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can conclude that the max_len can be chosen to be ___."
      ],
      "metadata": {
        "id": "2Gozk8y2p1os"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULbvRAH24w11"
      },
      "source": [
        "#Training Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by creating the dataset needed for training and testing, we will use the Dataset class from pytorch as our base class.\n",
        "\n",
        "For tokenization, we will be using the autotokenizer from HuggingFace."
      ],
      "metadata": {
        "id": "POaAvq9NtKHl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHazBYgbAugR"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers.data.processors.utils import InputFeatures\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "#define the Dataset class\n",
        "class SADataset(Dataset):\n",
        "  def __init__(self, texts, labels, model_name, max_len, label_map):\n",
        "    #hold the text and reviews inside the dataset class\n",
        "    self.texts = texts\n",
        "    self.labels = labels\n",
        "    self.label_map = label_map\n",
        "    self.tokenizer_name = model_name\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    #returns the length of the dataset\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    # Select the example based on the item ID\n",
        "    text = str(self.texts[item])\n",
        "    label = self.labels[item]\n",
        "\n",
        "    input_dict = self.tokenizer(\n",
        "          text,\n",
        "          add_special_tokens=True,\n",
        "          max_length=self.max_len,\n",
        "          padding = 'max_length',\n",
        "          truncation= True\n",
        "      )\n",
        "\n",
        "    return InputFeatures(input_ids=input_dict[\"input_ids\"],\n",
        "                         token_type_ids=input_dict['token_type_ids'],\n",
        "                         attention_mask=input_dict[\"attention_mask\"],\n",
        "                         label=self.label_map[self.labels[item]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4:** Define the evaluation metrics that we will need, including `accuracy_score`, `f1_score`, `precision_score` and `recall_score` from sklearn."
      ],
      "metadata": {
        "id": "5A70UoelxyYO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGPOnvGZRlVT"
      },
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    assert len(preds) == len(pred.label_ids)\n",
        "\n",
        "    pos_label = 1  # Assuming the positive label is represented by 1\n",
        "\n",
        "    if pos_label not in set(pred.label_ids):\n",
        "        raise ValueError(f\"Invalid pos_label: {pos_label}. Valid labels are {set(pred.label_ids)}.\")\n",
        "\n",
        "    macro_f1 = f1_score(pred.label_ids, preds, average='macro')\n",
        "    macro_f1_pos_neg = f1_score(pred.label_ids, preds, average='binary', pos_label=pos_label)\n",
        "    macro_precision = precision_score(pred.label_ids, preds, average='macro')\n",
        "    macro_recall = recall_score(pred.label_ids, preds, average='macro')\n",
        "    acc = accuracy_score(pred.label_ids, preds)\n",
        "\n",
        "    return {\n",
        "        'macro_f1': macro_f1,\n",
        "        'macro_f1_pos_neg': macro_f1_pos_neg,\n",
        "        'macro_precision': macro_precision,\n",
        "        'macro_recall': macro_recall,\n",
        "        'accuracy': acc\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcjtO-0N0u98"
      },
      "source": [
        "## Preprocess the dataset\n",
        "Let's start by defining the AraBERT preprocessor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbMtdGpB0t3w"
      },
      "source": [
        "from arabert.preprocess import ArabertPreprocessor\n",
        "\n",
        "model_name = 'aubmindlab/bert-base-arabertv02'\n",
        "arabert_prep = ArabertPreprocessor(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5:** Apply preprocessing for the text column using the arabert preprocessor:"
      ],
      "metadata": {
        "id": "RWKdP_IN1UpM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-wo9pTC0zXT"
      },
      "source": [
        "X_train = X_train.apply(lambda x: arabert_prep.preprocess(x))\n",
        "X_test = X_test.apply(lambda x: arabert_prep.preprocess(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's extract the label to id map:"
      ],
      "metadata": {
        "id": "GgfXN43X1gWV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDikUkPn2DqE",
        "outputId": "d5d97403-834c-4455-a2e6-caf62257fe0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "label_list = list(data[LABEL_COLUMN].unique())\n",
        "label_map = { v:index for index, v in enumerate(label_list) }\n",
        "print(label_map)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Positive': 0, 'Negative': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6:** Create the train and test SADataset:"
      ],
      "metadata": {
        "id": "1JfEWxXM1nDj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2zr1L_31e5J"
      },
      "source": [
        "max_len= 864\n",
        "train_dataset = SADataset(texts=X_train.tolist(), labels=Y_train.tolist(), model_name=model_name,\n",
        "                          max_len=max_len, label_map=label_map)\n",
        "\n",
        "test_dataset = SADataset(texts=X_test.tolist(), labels=Y_test.tolist(), model_name=model_name,\n",
        "                         max_len=max_len, label_map=label_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f0Tr_Jr4eAz"
      },
      "source": [
        "# Setup the HuggingFace trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using the `bert-base-arabertv02` from HuggingFace models by Antoun et Al (2020). We can choose other Arabic BERT models by just changing the path here from `https://huggingface.co/models`."
      ],
      "metadata": {
        "id": "vi_EhH9CqH_N"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVUtKhfwiyMZ",
        "outputId": "dca2ad34-9dd1-4c28-bc50-4cc6136f76d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=len(label_map))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now set up the training arguments, you can more information from https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments"
      ],
      "metadata": {
        "id": "UbLm8trS2NTg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BtOuUXX4JD0"
      },
      "source": [
        "from transformers import Trainer , TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= \"./train\",\n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 5e-5,\n",
        "    fp16 = True,\n",
        "    per_device_train_batch_size = 16,\n",
        "    per_device_eval_batch_size = 16,\n",
        "    gradient_accumulation_steps = 2,\n",
        "    num_train_epochs= 4,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'eval_macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 42\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ0Kxrs46QI9",
        "outputId": "02432ee5-123f-4f97-e7da-5f43f3b049cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_args.__dict__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'output_dir': './train',\n",
              " 'overwrite_output_dir': False,\n",
              " 'do_train': False,\n",
              " 'do_eval': True,\n",
              " 'do_predict': False,\n",
              " 'evaluation_strategy': <IntervalStrategy.EPOCH: 'epoch'>,\n",
              " 'prediction_loss_only': False,\n",
              " 'per_device_train_batch_size': 16,\n",
              " 'per_device_eval_batch_size': 16,\n",
              " 'per_gpu_train_batch_size': None,\n",
              " 'per_gpu_eval_batch_size': None,\n",
              " 'gradient_accumulation_steps': 2,\n",
              " 'eval_accumulation_steps': None,\n",
              " 'eval_delay': 0,\n",
              " 'learning_rate': 5e-05,\n",
              " 'weight_decay': 0.0,\n",
              " 'adam_beta1': 0.9,\n",
              " 'adam_beta2': 0.999,\n",
              " 'adam_epsilon': 1e-08,\n",
              " 'max_grad_norm': 1.0,\n",
              " 'num_train_epochs': 4,\n",
              " 'max_steps': -1,\n",
              " 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>,\n",
              " 'lr_scheduler_kwargs': {},\n",
              " 'warmup_ratio': 0.0,\n",
              " 'warmup_steps': 0,\n",
              " 'log_level': 'passive',\n",
              " 'log_level_replica': 'warning',\n",
              " 'log_on_each_node': True,\n",
              " 'logging_dir': './train/runs/Mar28_17-34-54_83bb468438b7',\n",
              " 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>,\n",
              " 'logging_first_step': False,\n",
              " 'logging_steps': 500,\n",
              " 'logging_nan_inf_filter': True,\n",
              " 'save_strategy': <IntervalStrategy.EPOCH: 'epoch'>,\n",
              " 'save_steps': 500,\n",
              " 'save_total_limit': None,\n",
              " 'save_safetensors': True,\n",
              " 'save_on_each_node': False,\n",
              " 'save_only_model': False,\n",
              " 'no_cuda': False,\n",
              " 'use_cpu': False,\n",
              " 'use_mps_device': False,\n",
              " 'seed': 42,\n",
              " 'data_seed': None,\n",
              " 'jit_mode_eval': False,\n",
              " 'use_ipex': False,\n",
              " 'bf16': False,\n",
              " 'fp16': True,\n",
              " 'fp16_opt_level': 'O1',\n",
              " 'half_precision_backend': 'auto',\n",
              " 'bf16_full_eval': False,\n",
              " 'fp16_full_eval': False,\n",
              " 'tf32': None,\n",
              " 'local_rank': 0,\n",
              " 'ddp_backend': None,\n",
              " 'tpu_num_cores': None,\n",
              " 'tpu_metrics_debug': False,\n",
              " 'debug': [],\n",
              " 'dataloader_drop_last': False,\n",
              " 'eval_steps': None,\n",
              " 'dataloader_num_workers': 0,\n",
              " 'dataloader_prefetch_factor': None,\n",
              " 'past_index': -1,\n",
              " 'run_name': './train',\n",
              " 'disable_tqdm': False,\n",
              " 'remove_unused_columns': True,\n",
              " 'label_names': None,\n",
              " 'load_best_model_at_end': True,\n",
              " 'metric_for_best_model': 'eval_macro_f1',\n",
              " 'greater_is_better': True,\n",
              " 'ignore_data_skip': False,\n",
              " 'fsdp': [],\n",
              " 'fsdp_min_num_params': 0,\n",
              " 'fsdp_config': {'min_num_params': 0,\n",
              "  'xla': False,\n",
              "  'xla_fsdp_v2': False,\n",
              "  'xla_fsdp_grad_ckpt': False},\n",
              " 'fsdp_transformer_layer_cls_to_wrap': None,\n",
              " 'accelerator_config': AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True),\n",
              " 'deepspeed': None,\n",
              " 'label_smoothing_factor': 0.0,\n",
              " 'optim': <OptimizerNames.ADAMW_TORCH: 'adamw_torch'>,\n",
              " 'optim_args': None,\n",
              " 'adafactor': False,\n",
              " 'group_by_length': False,\n",
              " 'length_column_name': 'length',\n",
              " 'report_to': ['tensorboard'],\n",
              " 'ddp_find_unused_parameters': None,\n",
              " 'ddp_bucket_cap_mb': None,\n",
              " 'ddp_broadcast_buffers': None,\n",
              " 'dataloader_pin_memory': True,\n",
              " 'dataloader_persistent_workers': False,\n",
              " 'skip_memory_metrics': True,\n",
              " 'use_legacy_prediction_loop': False,\n",
              " 'push_to_hub': False,\n",
              " 'resume_from_checkpoint': None,\n",
              " 'hub_model_id': None,\n",
              " 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>,\n",
              " 'hub_token': None,\n",
              " 'hub_private_repo': False,\n",
              " 'hub_always_push': False,\n",
              " 'gradient_checkpointing': False,\n",
              " 'gradient_checkpointing_kwargs': None,\n",
              " 'include_inputs_for_metrics': False,\n",
              " 'fp16_backend': 'auto',\n",
              " 'push_to_hub_model_id': None,\n",
              " 'push_to_hub_organization': None,\n",
              " 'push_to_hub_token': None,\n",
              " 'mp_parameters': '',\n",
              " 'auto_find_batch_size': False,\n",
              " 'full_determinism': False,\n",
              " 'torchdynamo': None,\n",
              " 'ray_scope': 'last',\n",
              " 'ddp_timeout': 1800,\n",
              " 'torch_compile': False,\n",
              " 'torch_compile_backend': None,\n",
              " 'torch_compile_mode': None,\n",
              " 'dispatch_batches': None,\n",
              " 'split_batches': None,\n",
              " 'include_tokens_per_second': False,\n",
              " 'include_num_input_tokens_seen': False,\n",
              " 'neftune_noise_alpha': None,\n",
              " 'distributed_state': Distributed environment: NO\n",
              " Num processes: 1\n",
              " Process index: 0\n",
              " Local process index: 0\n",
              " Device: cuda,\n",
              " '_n_gpu': 1,\n",
              " '__cached__setup_devices': device(type='cuda', index=0),\n",
              " 'deepspeed_plugin': None}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Initialize the Trainer and start training:"
      ],
      "metadata": {
        "id": "C7UNtb2J3b8F"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxuG93Aj5iiA"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvxxCSpI-yGG"
      },
      "source": [
        "#  Saving the best model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before saving the model, let's change the label2id in the config file, and get the id to label map."
      ],
      "metadata": {
        "id": "qma6qGK1-6rj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPCX0NUt51wS"
      },
      "source": [
        "trainer.model.config.label2id = label_map\n",
        "inv_label_map = { v:k for k, v in label_map.items()}\n",
        "trainer.model.config.id2label = inv_label_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1UFwVNs-6Dk",
        "outputId": "537575c8-7aaa-4087-b7bc-fcee2371c5f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#save the model in the folder\n",
        "trainer.save_model(\"best_sa_model\")\n",
        "test_dataset.tokenizer.save_pretrained(\"best_sa_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('best_sa_model/tokenizer_config.json',\n",
              " 'best_sa_model/special_tokens_map.json',\n",
              " 'best_sa_model/vocab.txt',\n",
              " 'best_sa_model/added_tokens.json',\n",
              " 'best_sa_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "422JyvSi_n0d"
      },
      "source": [
        "# Loading the model for inference\n",
        "We can use HuggingFace pipelines to load the model for inference:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzTSG6cp_g36"
      },
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\n",
        "        \"sentiment-analysis\",\n",
        "        model = \"best_sa_model\",\n",
        "        device=0, # set device to 0 for CUDA\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aJegKHL_zjk",
        "outputId": "a4884561-28a7-4a60-d9ea-2ad0207fcdd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pipe(\"انا لا احبك\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'Negative', 'score': 0.6347230672836304}]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"انا احبك\")"
      ],
      "metadata": {
        "id": "5Sl3tW71-v92",
        "outputId": "9ead7948-5768-4ef9-9e24-20850edb5eb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'Negative', 'score': 0.6554362773895264}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SwavP0EHJMxV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}